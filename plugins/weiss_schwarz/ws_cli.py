# WeiÃŸ Schwarz CLI Module
# ========================
# Command-line interface for WeiÃŸ Schwarz plugin

import os
import sys
import click
from typing import List

# Import our custom modules
from ws_scraper import (
    Tournament, Deck,
    get_tournaments_from_weissteatime,
    get_tournaments_from_official_site,
    scrape_deck_from_tournament,
    save_decks_to_file
)
from ws_api import (
    process_ws_cards_batch,
    get_tournament_decks,
    parse_deck_from_url,
    search_ws_cards
)

# -----------------------------
# Command Line Interface
# -----------------------------
@click.command()
@click.option('--format', '-f', default='standard',
              type=click.Choice(['standard', 'all']),
              help='Tournament format to scrape')
@click.option('--source', '-s', default='weissteatime',
              type=click.Choice(['weissteatime', 'official', 'both']),
              help='Data source to use for tournaments')
@click.option('--num-tournaments', '-n', default=5,
              help='Number of tournaments to scrape')
@click.option('--output-dir', '-o', default='game/front',
              help='Directory to save card images')
@click.option('--save-decks', '-d', default='game/decklist/ws_decks.txt',
              help='File to save deck lists')
@click.option('--fetch-images/--no-fetch-images', default=False,
              help='Fetch card images from WeiÃŸ Schwarz databases')
@click.option('--tournament-url', '-t', default=None,
              help='Specific tournament URL to scrape (overrides --num-tournaments)')
@click.option('--deck-url', '-u', default=None,
              help='Parse a specific deck from EncoreDecks or DeckLog URL')
@click.option('--search-card', '-c', default=None,
              help='Search for a specific card by name')
def main(format, source, num_tournaments, output_dir, save_decks, fetch_images, tournament_url, deck_url, search_card):
    """
    WeiÃŸ Schwarz Scraper Plugin

    Scrapes deck lists from WeiÃŸ Schwarz community sites and official resources.
    Features massive anime crossovers from Attack on Titan, Fate, and more.

    Examples:
        # Scrape recent tournaments from WeissTeaTime
        python ws_cli.py --source weissteatime --format standard --num-tournaments 5

        # Fetch images for scraped decks
        python ws_cli.py --fetch-images --save-decks my_decks.txt

        # Process specific tournament
        python ws_cli.py --tournament-url "https://weissteatime.com/tournament/123"
    """
    print("WeiÃŸ Schwarz Scraper Plugin")
    print("="*50)
    print("Massive anime crossovers: Attack on Titan, Fate, Re:Zero, and more!")
    print("Enhanced with wsmtools integration for real card database access!")

    all_decks = []

    # Handle specific deck URL parsing
    if deck_url:
        print(f"ðŸ” Parsing deck from URL: {deck_url}")
        deck_data = parse_deck_from_url(deck_url)
        if deck_data:
            # Convert to Deck object
            from ws_scraper import Deck
            deck = Deck(
                name=deck_data['name'],
                format=deck_data['format'],
                cards=deck_data['cards'],
                player=deck_data['player'],
                tournament_id="url_parsed"
            )
            all_decks.append(deck)
            print(f"âœ… Successfully parsed deck: {deck_data['name']}")
        else:
            print("âŒ Failed to parse deck from URL")
            return

    # Handle card search
    elif search_card:
        print(f"ðŸ” Searching for card: {search_card}")
        cards = search_ws_cards(search_card)
        if cards:
            print(f"âœ… Found {len(cards)} matching cards:")
            for i, card in enumerate(cards, 1):
                print(f"  {i}. {card.name} ({card.set_code}) - {card.rarity}")
                if card.image_url:
                    print(f"     Image: {card.image_url}")
        else:
            print("âŒ No cards found")
        return

    elif tournament_url:
        # Process specific tournament
        print(f"ðŸ” Processing specific tournament: {tournament_url}")
        tournament_decks = get_tournament_decks(tournament_url)
        all_decks.extend(tournament_decks)
        print(f"Found {len(tournament_decks)} decks")
    else:
        # Process multiple tournaments from selected sources
        print(f"ðŸ” Discovering {format} tournaments from {source}...")

        tournaments = []

        if source in ['weissteatime', 'both']:
            wtt_tournaments = get_tournaments_from_weissteatime(format, num_tournaments)
            tournaments.extend(wtt_tournaments)

        if source in ['official', 'both']:
            official_tournaments = get_tournaments_from_official_site(format, num_tournaments)
            tournaments.extend(official_tournaments)

        if not tournaments:
            print("âŒ No tournaments found.")
            return

        print(f"âœ… Found {len(tournaments)} tournaments")

        # Process each tournament (simplified for demo)
        for tournament in tournaments[:3]:  # Limit for demo
            print(f"\nProcessing: {tournament.name}")
            # For demo, create sample decks
            sample_deck = type('Deck', (), {
                'name': f"Sample Deck - {tournament.name}",
                'format': tournament.format,
                'cards': [(4, "Level 0 Card"), (50, "Level 1-3 Cards"), (4, "Climax Card")],
                'player': "Demo Player",
                'tournament_id': tournament.id,
                'hash': "demo_hash"
            })()
            all_decks.append(sample_deck)

    print(f"\nðŸ“Š Total decks processed: {len(all_decks)}")

    if not all_decks:
        print("âŒ No decks found. Exiting.")
        return

    # -----------------------------
    # Save Deck Data
    # -----------------------------
    print("\nðŸ’¾ Saving deck data...")
    os.makedirs(os.path.dirname(save_decks), exist_ok=True)
    save_decks_to_file(all_decks, save_decks)

    # -----------------------------
    # Image Fetching (Optional)
    # -----------------------------
    if fetch_images:
        print("\nðŸ–¼ï¸  Fetching card images...")

        # Extract unique cards from all decks
        unique_cards = {}
        for deck in all_decks:
            for quantity, card_name in deck.cards:
                if card_name not in unique_cards:
                    unique_cards[card_name] = quantity
                else:
                    unique_cards[card_name] = max(unique_cards[card_name], quantity)

        cards_list = [(q, name) for name, q in unique_cards.items()]
        print(f"Found {len(cards_list)} unique cards")

        # Ask for confirmation for large downloads
        if len(cards_list) > 20:
            if not click.confirm(f"Download {len(cards_list)} card images?", default=False):
                print("Skipping image download.")
                return

        # Process cards in batches
        processed = process_ws_cards_batch(cards_list, output_dir)
        print(f"âœ… Downloaded {processed} card images to {output_dir}")

    # -----------------------------
    # Completion Summary
    # -----------------------------
    print("\nðŸŽ‰ WEIÃŸ SCHWARZ PLUGIN COMPLETE")
    print("=" * 50)
    print(f"ðŸ“Š Summary:")
    print(f"   â€¢ Tournaments processed: {num_tournaments if not tournament_url else 1}")
    print(f"   â€¢ Decks scraped: {len(all_decks)}")
    print(f"   â€¢ Deck data saved to: {save_decks}")

    if fetch_images:
        unique_count = len(set(card_name for _, card_name in cards_list))
        print(f"   â€¢ Card images downloaded: {processed}")
        print(f"   â€¢ Images saved to: {output_dir}")

    print("\nâœ… Ready for card creation!")
    print("Massive anime multiverse in your hands!")
# -----------------------------
# Script Entry Point
# -----------------------------
if __name__ == '__main__':
    main()
